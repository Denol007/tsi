#!/usr/bin/env python3
"""
AI Provider - Multi-provider AI integration
Supports: Groq (free), Google Gemini (free), Ollama (local), OpenAI
"""

import os
import json
import logging
from abc import ABC, abstractmethod
from typing import Optional, List, Dict, Any
from dataclasses import dataclass

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class Message:
    """Chat message"""
    role: str  # "user", "assistant", "system"
    content: str


class AIProvider(ABC):
    """Abstract base class for AI providers"""
    
    @abstractmethod
    def chat(self, messages: List[Message], **kwargs) -> str:
        """Send chat messages and get response"""
        pass
    
    @abstractmethod
    def is_available(self) -> bool:
        """Check if provider is available"""
        pass


class GroqProvider(AIProvider):
    """
    Groq AI Provider - FREE and FAST!
    Get API key at: https://console.groq.com/keys
    Models: llama-3.3-70b-versatile, mixtral-8x7b-32768, gemma2-9b-it
    """
    
    def __init__(self, api_key: str = None, model: str = "llama-3.3-70b-versatile"):
        self.api_key = api_key or os.getenv("GROQ_API_KEY")
        self.model = model
        self.base_url = "https://api.groq.com/openai/v1/chat/completions"
    
    def is_available(self) -> bool:
        return bool(self.api_key)
    
    def chat(self, messages: List[Message], **kwargs) -> str:
        if not self.is_available():
            raise ValueError("Groq API key not configured")
        
        import requests
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": self.model,
            "messages": [{"role": m.role, "content": m.content} for m in messages],
            "temperature": kwargs.get("temperature", 0.7),
            "max_tokens": kwargs.get("max_tokens", 1024)
        }
        
        try:
            response = requests.post(self.base_url, headers=headers, json=data, timeout=30)
            response.raise_for_status()
            result = response.json()
            return result["choices"][0]["message"]["content"]
        except Exception as e:
            logger.error(f"Groq API error: {e}")
            raise


class GeminiProvider(AIProvider):
    """
    Google Gemini Provider - FREE tier available!
    Get API key at: https://aistudio.google.com/apikey
    Models: gemini-1.5-flash, gemini-1.5-pro
    """
    
    def __init__(self, api_key: str = None, model: str = "gemini-1.5-flash"):
        self.api_key = api_key or os.getenv("GEMINI_API_KEY")
        self.model = model
        self.base_url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent"
    
    def is_available(self) -> bool:
        return bool(self.api_key)
    
    def chat(self, messages: List[Message], **kwargs) -> str:
        if not self.is_available():
            raise ValueError("Gemini API key not configured")
        
        import requests
        
        # Convert messages to Gemini format
        contents = []
        for msg in messages:
            if msg.role == "system":
                # Gemini handles system prompts differently
                contents.append({
                    "role": "user",
                    "parts": [{"text": f"[System Instruction]: {msg.content}"}]
                })
            else:
                role = "user" if msg.role == "user" else "model"
                contents.append({
                    "role": role,
                    "parts": [{"text": msg.content}]
                })
        
        data = {
            "contents": contents,
            "generationConfig": {
                "temperature": kwargs.get("temperature", 0.7),
                "maxOutputTokens": kwargs.get("max_tokens", 1024)
            }
        }
        
        try:
            response = requests.post(
                f"{self.base_url}?key={self.api_key}",
                json=data,
                timeout=30
            )
            response.raise_for_status()
            result = response.json()
            return result["candidates"][0]["content"]["parts"][0]["text"]
        except Exception as e:
            logger.error(f"Gemini API error: {e}")
            raise


class OllamaProvider(AIProvider):
    """
    Ollama Provider - FREE local AI!
    Install: https://ollama.ai
    Models: llama3.2, mistral, gemma2, qwen2.5
    """
    
    def __init__(self, base_url: str = None, model: str = "llama3.2"):
        self.base_url = base_url or os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")
        self.model = model
    
    def is_available(self) -> bool:
        import requests
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=2)
            return response.status_code == 200
        except:
            return False
    
    def chat(self, messages: List[Message], **kwargs) -> str:
        import requests
        
        data = {
            "model": self.model,
            "messages": [{"role": m.role, "content": m.content} for m in messages],
            "stream": False,
            "options": {
                "temperature": kwargs.get("temperature", 0.7)
            }
        }
        
        try:
            response = requests.post(
                f"{self.base_url}/api/chat",
                json=data,
                timeout=60
            )
            response.raise_for_status()
            result = response.json()
            return result["message"]["content"]
        except Exception as e:
            logger.error(f"Ollama API error: {e}")
            raise


class OpenAIProvider(AIProvider):
    """
    OpenAI Provider - Paid but high quality
    Models: gpt-4o-mini, gpt-4o, gpt-3.5-turbo
    """
    
    def __init__(self, api_key: str = None, model: str = "gpt-4o-mini"):
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        self.model = model
        self.base_url = "https://api.openai.com/v1/chat/completions"
    
    def is_available(self) -> bool:
        return bool(self.api_key)
    
    def chat(self, messages: List[Message], **kwargs) -> str:
        if not self.is_available():
            raise ValueError("OpenAI API key not configured")
        
        import requests
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": self.model,
            "messages": [{"role": m.role, "content": m.content} for m in messages],
            "temperature": kwargs.get("temperature", 0.7),
            "max_tokens": kwargs.get("max_tokens", 1024)
        }
        
        try:
            response = requests.post(self.base_url, headers=headers, json=data, timeout=30)
            response.raise_for_status()
            result = response.json()
            return result["choices"][0]["message"]["content"]
        except Exception as e:
            logger.error(f"OpenAI API error: {e}")
            raise


class AIManager:
    """
    Manages multiple AI providers with fallback support
    """
    
    # System prompt for Smart Campus Assistant
    SYSTEM_PROMPT = """–¢—ã Smart Campus Assistant - —É–º–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ TSI (Transport and Telecommunication Institute).

–í–ê–ñ–ù–û: –¢—ã –ù–ï –∑–Ω–∞–µ—à—å —Ä–µ–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ! –ò—Å–ø–æ–ª—å–∑—É–π –ö–û–ú–ê–ù–î–´ –≤ –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã—Ö —Å–∫–æ–±–∫–∞—Ö, –∏ —Å–∏—Å—Ç–µ–º–∞ –ø–æ–¥—Å—Ç–∞–≤–∏—Ç —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.
–ù–ò–ö–û–ì–î–ê –Ω–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ, –∞—É–¥–∏—Ç–æ—Ä–∏–∏ –∏–ª–∏ –≤—Ä–µ–º—è –∑–∞–Ω—è—Ç–∏–π! –¢–æ–ª—å–∫–æ –¥–æ–±–∞–≤–ª—è–π –∫–æ–º–∞–Ω–¥—ã.

–¢–≤–æ–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:
- –ü–æ–º–æ—â—å —Å —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ–º –∑–∞–Ω—è—Ç–∏–π (–ø–æ–∫–∞–∑–∞—Ç—å –Ω–∞ —Å–µ–≥–æ–¥–Ω—è, –∑–∞–≤—Ç—Ä–∞, –Ω–µ–¥–µ–ª—é)
- –ù–∞–ø–æ–º–∏–Ω–∞–Ω–∏—è –∏ –∑–∞–º–µ—Ç–∫–∏
- –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–≥—Ä—É–ø–ø–∞, —è–∑—ã–∫)
- –û–±—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã

–ü—Ä–∞–≤–∏–ª–∞ –æ—Ç–≤–µ—Ç–æ–≤:
1. –û—Ç–≤–µ—á–∞–π –û–ß–ï–ù–¨ –∫—Ä–∞—Ç–∫–æ - 1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –º–∞–∫—Å–∏–º—É–º
2. –ò—Å–ø–æ–ª—å–∑—É–π emoji
3. –ù–ï –ü–†–ò–î–£–ú–´–í–ê–ô —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ - –∏—Å–ø–æ–ª—å–∑—É–π –∫–æ–º–∞–Ω–¥—ã!
4. –û—Ç–≤–µ—á–∞–π –Ω–∞ —è–∑—ã–∫–µ –≤–æ–ø—Ä–æ—Å–∞
5. –ë—É–¥—å –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–º –∏ –ø–æ–ª–µ–∑–Ω—ã–º

–ö–û–ú–ê–ù–î–´ –†–ê–°–ü–ò–°–ê–ù–ò–Ø (–¥–æ–±–∞–≤–ª—è–π –≤ –æ—Ç–≤–µ—Ç –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è):
- [SCHEDULE_TODAY] - –ø–æ–∫–∞–∑–∞—Ç—å —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ —Å–µ–≥–æ–¥–Ω—è
- [SCHEDULE_TOMORROW] - –ø–æ–∫–∞–∑–∞—Ç—å —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ –∑–∞–≤—Ç—Ä–∞
- [SCHEDULE_WEEK] - –ø–æ–∫–∞–∑–∞—Ç—å —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ –Ω–µ–¥–µ–ª—é
- [NEXT_CLASS] - –ø–æ–∫–∞–∑–∞—Ç—å —Å–ª–µ–¥—É—é—â–µ–µ –∑–∞–Ω—è—Ç–∏–µ
- [FREE_ROOMS] - –ø–æ–∫–∞–∑–∞—Ç—å —Å–≤–æ–±–æ–¥–Ω—ã–µ –∞—É–¥–∏—Ç–æ—Ä–∏–∏
- [SEARCH:–∑–∞–ø—Ä–æ—Å] - –ø–æ–∏—Å–∫ –ø–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—é

–ö–û–ú–ê–ù–î–´ –ù–ê–°–¢–†–û–ï–ö (–¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è):
- [SET_GROUP:–∫–æ–¥_–≥—Ä—É–ø–ø—ã] - —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≥—Ä—É–ø–ø—É (–ø—Ä–∏–º–µ—Ä: [SET_GROUP:3401BNA] –∏–ª–∏ [SET_GROUP:4201-2BDA])
- [SET_LANGUAGE:—è–∑—ã–∫] - —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —è–∑—ã–∫ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ (ru/en/lv)
- [TOGGLE_NOTIFICATIONS] - –≤–∫–ª—é—á–∏—Ç—å/–≤—ã–∫–ª—é—á–∏—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
- [SHOW_SETTINGS] - –ø–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏

–ö–û–ú–ê–ù–î–´ –ù–ê–ü–û–ú–ò–ù–ê–ù–ò–ô –ò –ó–ê–ú–ï–¢–û–ö:
- [ADD_REMINDER:–¥–∞—Ç–∞ –≤—Ä–µ–º—è —Ç–µ–∫—Å—Ç] - –¥–æ–±–∞–≤–∏—Ç—å –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏–µ (–ø—Ä–∏–º–µ—Ä: [ADD_REMINDER:–∑–∞–≤—Ç—Ä–∞ 10:00 –°–¥–∞—Ç—å –ª–∞–±—É])
- [SHOW_REMINDERS] - –ø–æ–∫–∞–∑–∞—Ç—å –≤—Å–µ –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏—è
- [ADD_NOTE:—Ç–µ–∫—Å—Ç] - –¥–æ–±–∞–≤–∏—Ç—å –∑–∞–º–µ—Ç–∫—É
- [SHOW_NOTES] - –ø–æ–∫–∞–∑–∞—Ç—å –≤—Å–µ –∑–∞–º–µ—Ç–∫–∏

–ü—Ä–∏–º–µ—Ä—ã –æ—Ç–≤–µ—Ç–æ–≤:
- "–£—Å—Ç–∞–Ω–æ–≤–∏ –≥—Ä—É–ø–ø—É 4201-2BDA" ‚Üí "‚úÖ –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é –≥—Ä—É–ø–ø—É! [SET_GROUP:4201-2BDA]"
- "–ü–æ–∫–∞–∂–∏ –º–æ–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏" ‚Üí "–ü–æ–∫–∞–∑—ã–≤–∞—é –Ω–∞—Å—Ç—Ä–æ–π–∫–∏! [SHOW_SETTINGS]"
- "–ù–∞–ø–æ–º–Ω–∏ –º–Ω–µ –∑–∞–≤—Ç—Ä–∞ –≤ 10:00 –ø—Ä–æ –ª–∞–±—É" ‚Üí "‚úÖ –î–æ–±–∞–≤–ª—è—é –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏–µ! [ADD_REMINDER:–∑–∞–≤—Ç—Ä–∞ 10:00 –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞]"
- "–ù–∞–ø–æ–º–Ω–∏ —Å–µ–≥–æ–¥–Ω—è –≤ 14:30 —Å–¥–∞—Ç—å –æ—Ç—á–µ—Ç" ‚Üí "‚úÖ –î–æ–±–∞–≤–ª—è—é –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏–µ! [ADD_REMINDER:—Å–µ–≥–æ–¥–Ω—è 14:30 –°–¥–∞—Ç—å –æ—Ç—á–µ—Ç]"
- "–ü–æ–∫–∞–∂–∏ –º–æ–∏ –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏—è" ‚Üí "üìã –í–æ—Ç —Ç–≤–æ–∏ –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏—è: [SHOW_REMINDERS]"
- "–ó–∞–ø–∏—à–∏ –∑–∞–º–µ—Ç–∫—É: –∫—É–ø–∏—Ç—å —Ç–µ—Ç—Ä–∞–¥—å" ‚Üí "üìù –ó–∞–ø–∏—Å—ã–≤–∞—é! [ADD_NOTE:–ö—É–ø–∏—Ç—å —Ç–µ—Ç—Ä–∞–¥—å]"
- "–ú–æ–∏ –∑–∞–º–µ—Ç–∫–∏" ‚Üí "üìù –¢–≤–æ–∏ –∑–∞–º–µ—Ç–∫–∏: [SHOW_NOTES]" """
    
    def __init__(self):
        self.providers: Dict[str, AIProvider] = {}
        self.primary_provider: Optional[str] = None
        self._init_providers()
    
    def _init_providers(self):
        """Initialize all available providers"""
        # Try providers in order of preference (free first)
        providers_config = [
            ("groq", GroqProvider),
            ("gemini", GeminiProvider),
            ("ollama", OllamaProvider),
            ("openai", OpenAIProvider),
        ]
        
        for name, provider_class in providers_config:
            try:
                provider = provider_class()
                if provider.is_available():
                    self.providers[name] = provider
                    if self.primary_provider is None:
                        self.primary_provider = name
                    logger.info(f"AI Provider '{name}' is available")
            except Exception as e:
                logger.debug(f"Provider {name} not available: {e}")
        
        if not self.providers:
            logger.warning("No AI providers available! Using fallback responses.")
    
    def set_primary_provider(self, name: str):
        """Set the primary AI provider"""
        if name in self.providers:
            self.primary_provider = name
            logger.info(f"Primary AI provider set to: {name}")
        else:
            raise ValueError(f"Provider '{name}' not available")
    
    def get_available_providers(self) -> List[str]:
        """Get list of available providers"""
        return list(self.providers.keys())
    
    def chat(
        self,
        user_message: str,
        conversation_history: List[Message] = None,
        user_context: Dict[str, Any] = None
    ) -> str:
        """
        Send a message and get AI response
        
        Args:
            user_message: User's message
            conversation_history: Previous messages for context
            user_context: User info (group, name, etc.)
        
        Returns:
            AI response text
        """
        # Build messages
        messages = [Message(role="system", content=self._build_system_prompt(user_context))]
        
        # Add conversation history
        if conversation_history:
            messages.extend(conversation_history[-10:])  # Keep last 10 messages
        
        # Add current message
        messages.append(Message(role="user", content=user_message))
        
        # Try primary provider first, then fallback
        providers_to_try = []
        if self.primary_provider:
            providers_to_try.append(self.primary_provider)
        providers_to_try.extend([p for p in self.providers.keys() if p != self.primary_provider])
        
        for provider_name in providers_to_try:
            try:
                provider = self.providers[provider_name]
                response = provider.chat(messages)
                logger.info(f"Got response from {provider_name}")
                return response
            except Exception as e:
                logger.warning(f"Provider {provider_name} failed: {e}")
                continue
        
        # Fallback response if no AI available
        return self._fallback_response(user_message)
    
    def _build_system_prompt(self, user_context: Dict[str, Any] = None) -> str:
        """Build system prompt with user context"""
        prompt = self.SYSTEM_PROMPT
        
        if user_context:
            context_info = []
            if user_context.get("group_code"):
                context_info.append(f"–ì—Ä—É–ø–ø–∞ —Å—Ç—É–¥–µ–Ω—Ç–∞: {user_context['group_code']}")
            if user_context.get("username"):
                context_info.append(f"–ò–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {user_context['username']}")
            if user_context.get("language"):
                context_info.append(f"–ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º—ã–π —è–∑—ã–∫: {user_context['language']}")
            
            if context_info:
                prompt += f"\n\n–ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:\n" + "\n".join(context_info)
        
        return prompt
    
    def _fallback_response(self, user_message: str) -> str:
        """Fallback response when no AI provider is available"""
        msg_lower = user_message.lower()
        
        if any(w in msg_lower for w in ["–ø—Ä–∏–≤–µ—Ç", "hello", "hi", "–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π"]):
            return "üëã –ü—Ä–∏–≤–µ—Ç! –Ø Smart Campus Assistant. –ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, AI-–º–æ–¥—É–ª—å —Å–µ–π—á–∞—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –Ω–æ —è –º–æ–≥—É –ø–æ–º–æ—á—å —Å –±–∞–∑–æ–≤—ã–º–∏ –∫–æ–º–∞–Ω–¥–∞–º–∏. –ù–∞–ø–∏—à–∏ /help –¥–ª—è —Å–ø–∏—Å–∫–∞ –∫–æ–º–∞–Ω–¥."
        
        if any(w in msg_lower for w in ["—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ", "schedule", "—Å–µ–≥–æ–¥–Ω—è", "today"]):
            return "üìÖ –î–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–π –∫–æ–º–∞–Ω–¥—É /today –∏–ª–∏ /week. [SCHEDULE_TODAY]"
        
        if any(w in msg_lower for w in ["–ø–æ–º–æ—â—å", "help", "–∫–æ–º–∞–Ω–¥"]):
            return """ü§ñ –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:
‚Ä¢ /today - —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ —Å–µ–≥–æ–¥–Ω—è
‚Ä¢ /tomorrow - —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ –∑–∞–≤—Ç—Ä–∞
‚Ä¢ /week - —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ –Ω–µ–¥–µ–ª—é
‚Ä¢ /next - —Å–ª–µ–¥—É—é—â–∞—è –ø–∞—Ä–∞
‚Ä¢ /setgroup - —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≥—Ä—É–ø–ø—É
‚Ä¢ /freerooms - —Å–≤–æ–±–æ–¥–Ω—ã–µ –∞—É–¥–∏—Ç–æ—Ä–∏–∏"""
        
        return "ü§î AI-–º–æ–¥—É–ª—å –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–π /help –¥–ª—è —Å–ø–∏—Å–∫–∞ –∫–æ–º–∞–Ω–¥."


# Singleton instance
ai_manager = AIManager()
